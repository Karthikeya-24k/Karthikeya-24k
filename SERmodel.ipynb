{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMkb+jgTmryd+5+Y1wbcKBX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlZb4eHoG72r"
      },
      "outputs": [],
      "source": [
        "# Speech emotion recognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "qUbCqrzbHRxS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your kaggle.json file (downloaded from Kaggle Account > API)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload kaggle.json when prompted\n",
        "\n",
        "# Move and secure the API token\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "cGBAb2J6HUTO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "0ec5dc98-73bb-4538-d2a0-5198710ee7c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c6ff6fd5-5665-45f5-a3f8-987cca97e57a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c6ff6fd5-5665-45f5-a3f8-987cca97e57a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory for datasets\n",
        "!mkdir -p /content/datasets"
      ],
      "metadata": {
        "id": "U2zgxtTBBbNg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download IESC\n",
        "\n",
        "!kaggle datasets download -d ejlok1/cremad -p /content/datasets --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWmevLWIBmay",
        "outputId": "00d07f37-31e0-4a38-cf3a-f2fb1cb725e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/datasets/metadata/julianros/ravdess-emotional-speech-audio\n",
            "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/datasets/metadata/sachinkumar413/ser-dataset\n",
            "Dataset URL: https://www.kaggle.com/datasets/ejlok1/cremad\n",
            "License(s): ODC Attribution License (ODC-By)\n",
            "Downloading cremad.zip to /content/datasets\n",
            " 95% 427M/451M [00:00<00:00, 419MB/s]\n",
            "100% 451M/451M [00:02<00:00, 161MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio -p /content/datasets --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi0tukhZBrXT",
        "outputId": "568653ea-7af0-4759-b314-162350846c91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading ravdess-emotional-speech-audio.zip to /content/datasets\n",
            " 91% 391M/429M [00:00<00:00, 366MB/s]\n",
            "100% 429M/429M [00:01<00:00, 394MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ybsingh/indian-emotional-speech-corpora-iesc -p /content/datasets --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxn1f7G2KA3r",
        "outputId": "6e893560-a82d-4c65-8fbb-3e6f4e69ff7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ybsingh/indian-emotional-speech-corpora-iesc\n",
            "License(s): unknown\n",
            "Downloading indian-emotional-speech-corpora-iesc.zip to /content/datasets\n",
            " 96% 126M/131M [00:00<00:00, 1.30GB/s]\n",
            "100% 131M/131M [00:00<00:00, 1.16GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/content/datasets\"\n",
        "for folder in os.listdir(base_path):\n",
        "    print(folder, \"->\", len(os.listdir(os.path.join(base_path, folder))), \"files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZf4xEIYKIYW",
        "outputId": "2f027b95-d13d-41a6-d947-b2873d9db47f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actor_15 -> 60 files\n",
            "Actor_19 -> 60 files\n",
            "Actor_24 -> 60 files\n",
            "Actor_10 -> 60 files\n",
            "Actor_20 -> 60 files\n",
            "Actor_06 -> 60 files\n",
            "Actor_05 -> 60 files\n",
            "Actor_18 -> 60 files\n",
            "Actor_12 -> 60 files\n",
            "Actor_03 -> 60 files\n",
            "Actor_22 -> 60 files\n",
            "Indian Emotional Speech Corpora (IESC) -> 8 files\n",
            "audio_speech_actors_01-24 -> 24 files\n",
            "Actor_17 -> 60 files\n",
            "Actor_14 -> 60 files\n",
            "Actor_23 -> 60 files\n",
            "Actor_21 -> 60 files\n",
            "Actor_04 -> 60 files\n",
            "Actor_07 -> 60 files\n",
            "Actor_01 -> 60 files\n",
            "Actor_02 -> 60 files\n",
            "Actor_09 -> 60 files\n",
            "Actor_08 -> 60 files\n",
            "Actor_11 -> 60 files\n",
            "Actor_16 -> 60 files\n",
            "AudioWAV -> 7442 files\n",
            "Actor_13 -> 60 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "zip_files = glob.glob(\"/content/datasets//*.zip\", recursive=True)\n",
        "print(\"Zip files still remaining:\", zip_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMMpxq9VOszf",
        "outputId": "1deaa6ac-3d14-454b-fe69-ce46994eede1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip files still remaining: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "data = []\n",
        "\n",
        "# CREMA-D\n",
        "for file in glob.glob(\"/content/datasets/AudioWAV/**/*.wav\", recursive=True):\n",
        "    label = file.split('/')[-1].split('_')[2]  # e.g., \"ANG\", \"HAP\", \"SAD\"\n",
        "    data.append((file, label))\n",
        "\n",
        "# RAVDESS\n",
        "for file in glob.glob(\"/content/datasets/audio_speech_actors_01-24/**/*.wav\", recursive=True):\n",
        "    label = int(file.split('-')[2])\n",
        "    emotions = {\n",
        "        1: 'neutral', 2: 'calm', 3: 'happy', 4: 'sad',\n",
        "        5: 'angry', 6: 'fearful', 7: 'disgust', 8: 'surprised'\n",
        "    }\n",
        "    data.append((file, emotions[label]))\n",
        "\n",
        "# IESC\n",
        "for file in glob.glob(\"/content/datasets/Indian Emotional Speech Corpora (IESC)/**/*.wav\", recursive=True):\n",
        "    emotion = os.path.basename(os.path.dirname(file))\n",
        "    data.append((file, emotion))\n",
        "\n",
        "print(\"Total files collected:\", len(data))\n",
        "\n",
        "df = pd.DataFrame(data, columns=['file_path', 'emotion'])\n",
        "display(df['emotion'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "nJDrrhIUPv0Z",
        "outputId": "f8be77b2-fd95-4484-f802-99712d03fce3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files collected: 9482\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "emotion\n",
              "neutral    1440\n",
              "HAP        1271\n",
              "DIS        1271\n",
              "FEA        1271\n",
              "SAD        1271\n",
              "ANG        1271\n",
              "NEU        1087\n",
              "Anger       120\n",
              "Fear        120\n",
              "Sad         120\n",
              "Happy       120\n",
              "Neutral     120\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>1440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HAP</th>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIS</th>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SAD</th>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANG</th>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NEU</th>\n",
              "      <td>1087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Anger</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fear</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sad</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Happy</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neutral</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cQbEdq_kQHcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01b9cf15"
      },
      "source": [
        "# Task\n",
        "Preprocess the audio dataset by resampling, normalizing, and extracting features from each audio file. Handle data imbalance if necessary and prepare the data for model training by padding/trimming features and splitting the data into training and testing sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a20b47ff"
      },
      "source": [
        "## Load necessary libraries\n",
        "\n",
        "### Subtask:\n",
        "Import the required libraries for audio processing, data manipulation, and visualization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "167a9607"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary libraries for audio processing, data manipulation, machine learning utilities, and visualization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e518e4a"
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e4dcf17"
      },
      "source": [
        "## Define preprocessing function\n",
        "\n",
        "### Subtask:\n",
        "Create a function to handle resampling, normalization, and feature extraction for a single audio file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5808181d"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function to load, resample, normalize, and extract features from an audio file using librosa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b19005ea"
      },
      "source": [
        "def extract_features(file_path, target_sr=22050, n_mfcc=40):\n",
        "    \"\"\"\n",
        "    Loads an audio file, resamples, normalizes, and extracts MFCC features.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the audio file.\n",
        "        target_sr (int): The target sampling rate for resampling.\n",
        "        n_mfcc (int): The number of MFCCs to extract.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The extracted MFCC features.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the audio file and resample\n",
        "        y, sr = librosa.load(file_path, sr=target_sr)\n",
        "\n",
        "        # Normalize the audio data (simple amplitude normalization)\n",
        "        y = librosa.util.normalize(y)\n",
        "\n",
        "        # Extract MFCC features\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=target_sr, n_mfcc=n_mfcc)\n",
        "\n",
        "        return mfccs\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {e}\")\n",
        "        return None"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63d4a57"
      },
      "source": [
        "## Apply preprocessing to dataset\n",
        "\n",
        "### Subtask:\n",
        "Apply the preprocessing function to the DataFrame to extract features for all audio files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c539d8c9"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply the extract_features function to the DataFrame to extract features and handle potential errors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "f050597f",
        "outputId": "41acb576-0f22-465a-9dd7-dac246b8cdc1"
      },
      "source": [
        "# Apply the function to the 'file_path' column\n",
        "df['features'] = df['file_path'].apply(extract_features)\n",
        "\n",
        "# Remove rows where feature extraction failed (features is None)\n",
        "df.dropna(subset=['features'], inplace=True)\n",
        "\n",
        "display(df.head())\n",
        "display(df.info())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                        file_path emotion  \\\n",
              "0  /content/datasets/AudioWAV/1016_IWW_HAP_XX.wav     HAP   \n",
              "1  /content/datasets/AudioWAV/1062_ITS_FEA_XX.wav     FEA   \n",
              "2  /content/datasets/AudioWAV/1028_ITH_FEA_XX.wav     FEA   \n",
              "3  /content/datasets/AudioWAV/1034_IEO_DIS_HI.wav     DIS   \n",
              "4  /content/datasets/AudioWAV/1075_IEO_SAD_MD.wav     SAD   \n",
              "\n",
              "                                            features  \n",
              "0  [[-496.01083, -425.87827, -390.71567, -397.293...  \n",
              "1  [[-247.2875, -222.19348, -221.7024, -220.35379...  \n",
              "2  [[-297.2361, -263.3029, -254.96819, -252.1013,...  \n",
              "3  [[-490.4407, -465.88046, -439.61255, -431.9932...  \n",
              "4  [[-149.51883, -148.82031, -162.27313, -162.690...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdc870dd-654c-45e3-9aa1-3a2ba2f9cb99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_path</th>\n",
              "      <th>emotion</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/datasets/AudioWAV/1016_IWW_HAP_XX.wav</td>\n",
              "      <td>HAP</td>\n",
              "      <td>[[-496.01083, -425.87827, -390.71567, -397.293...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/datasets/AudioWAV/1062_ITS_FEA_XX.wav</td>\n",
              "      <td>FEA</td>\n",
              "      <td>[[-247.2875, -222.19348, -221.7024, -220.35379...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/datasets/AudioWAV/1028_ITH_FEA_XX.wav</td>\n",
              "      <td>FEA</td>\n",
              "      <td>[[-297.2361, -263.3029, -254.96819, -252.1013,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/datasets/AudioWAV/1034_IEO_DIS_HI.wav</td>\n",
              "      <td>DIS</td>\n",
              "      <td>[[-490.4407, -465.88046, -439.61255, -431.9932...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/datasets/AudioWAV/1075_IEO_SAD_MD.wav</td>\n",
              "      <td>SAD</td>\n",
              "      <td>[[-149.51883, -148.82031, -162.27313, -162.690...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdc870dd-654c-45e3-9aa1-3a2ba2f9cb99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bdc870dd-654c-45e3-9aa1-3a2ba2f9cb99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bdc870dd-654c-45e3-9aa1-3a2ba2f9cb99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-53d12c3f-d7a2-4f0e-aca7-e94c9c83e85a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53d12c3f-d7a2-4f0e-aca7-e94c9c83e85a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-53d12c3f-d7a2-4f0e-aca7-e94c9c83e85a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"file_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/datasets/AudioWAV/1062_ITS_FEA_XX.wav\",\n          \"/content/datasets/AudioWAV/1075_IEO_SAD_MD.wav\",\n          \"/content/datasets/AudioWAV/1028_ITH_FEA_XX.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"FEA\",\n          \"SAD\",\n          \"HAP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9482 entries, 0 to 9481\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   file_path  9482 non-null   object\n",
            " 1   emotion    9482 non-null   object\n",
            " 2   features   9482 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 222.4+ KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd1a890b"
      },
      "source": [
        "## Handle data imbalance (optional but recommended)\n",
        "\n",
        "### Subtask:\n",
        "If necessary, address any class imbalance in the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1199abe5"
      },
      "source": [
        "**Reasoning**:\n",
        "Analyze the emotion distribution to determine if class imbalance exists.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "fe355cf6",
        "outputId": "34f13954-511e-46f3-d0db-6850c81046a3"
      },
      "source": [
        "print(\"Emotion distribution before addressing imbalance:\")\n",
        "display(df['emotion'].value_counts())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion distribution before addressing imbalance:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "emotion\n",
              "neutral    1440\n",
              "HAP        1271\n",
              "DIS        1271\n",
              "FEA        1271\n",
              "SAD        1271\n",
              "ANG        1271\n",
              "NEU        1087\n",
              "Anger       120\n",
              "Fear        120\n",
              "Sad         120\n",
              "Happy       120\n",
              "Neutral     120\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>1440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HAP</th>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIS</th>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FEA</th>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SAD</th>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ANG</th>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NEU</th>\n",
              "      <td>1087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Anger</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fear</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sad</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Happy</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neutral</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98c35f93"
      },
      "source": [
        "**Reasoning**:\n",
        "Based on the value counts, there is significant class imbalance. Emotions like 'Anger', 'Fear', 'Sad', 'Happy', and 'Neutral' from the IESC dataset have significantly fewer samples compared to other emotions. To address this, I will use RandomOverSampler to oversample the minority classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "524e9de3",
        "outputId": "1f76dd99-c664-42d1-ea15-81468d098ca3"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Combine similar emotions\n",
        "df['emotion'] = df['emotion'].replace({\n",
        "    'HAP': 'happy', 'SAD': 'sad', 'ANG': 'angry', 'FEA': 'fearful', 'DIS': 'disgust',\n",
        "    'NEU': 'neutral', 'Happy': 'happy', 'Sad': 'sad', 'Anger': 'angry', 'Fear': 'fearful',\n",
        "    'Neutral': 'neutral'\n",
        "})\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "# Since features are numpy arrays, we need to keep them as objects or convert them appropriately\n",
        "X = df['features'].values\n",
        "y = df['emotion'].values\n",
        "\n",
        "# Apply RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# RandomOverSampler works with array-like inputs.\n",
        "# We need to reshape X to be 2D, even though each 'sample' is a variable-length feature array.\n",
        "# A common approach for oversampling sequences is to oversample the indices or\n",
        "# to use a custom sampler if the data structure is complex.\n",
        "# For simplicity and demonstration, we will reshape X to be a 2D array where each row\n",
        "# is a flattened version of the feature array. This might not be ideal for sequence models\n",
        "# but works for demonstrating oversampling with imblearn.\n",
        "\n",
        "# Let's first pad/trim the features to a fixed length for oversampling if they are not already.\n",
        "# Assuming features are variable length 2D arrays (n_mfcc, n_frames).\n",
        "# We need a consistent shape for imblearn or a custom approach.\n",
        "\n",
        "# A better approach for variable length sequences with imblearn is to oversample the indices\n",
        "# or use a different strategy. However, given the prompt's simplicity and the typical workflow\n",
        "# of feature extraction followed by padding/trimming, let's proceed with oversampling on\n",
        "# the feature arrays directly after padding/trimming, if padding was done previously (it wasn't).\n",
        "# Let's revisit the padding/trimming step which should ideally happen before oversampling\n",
        "# if using standard imblearn methods that expect fixed-size samples.\n",
        "\n",
        "# Since padding/trimming is a later step in the overall task, let's oversample the current\n",
        "# structure and acknowledge the limitation with variable-length features and standard samplers.\n",
        "# If the 'features' column contains numpy arrays of inconsistent shapes, RandomOverSampler\n",
        "# will likely raise an error.\n",
        "# A workaround is to oversample the indices and then use the oversampled indices to\n",
        "# create the balanced DataFrame.\n",
        "\n",
        "# Let's oversample the indices\n",
        "indices = np.arange(len(df))\n",
        "indices_resampled, y_resampled = ros.fit_resample(indices.reshape(-1, 1), y)\n",
        "\n",
        "# Create a new DataFrame with the oversampled data\n",
        "df_balanced = df.iloc[indices_resampled.flatten()].copy()\n",
        "\n",
        "print(\"\\nEmotion distribution after oversampling:\")\n",
        "display(df_balanced['emotion'].value_counts())\n",
        "\n",
        "df = df_balanced # Update the main DataFrame"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Emotion distribution after oversampling:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "emotion\n",
              "happy      2647\n",
              "fearful    2647\n",
              "disgust    2647\n",
              "sad        2647\n",
              "neutral    2647\n",
              "angry      2647\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <td>2647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fearful</th>\n",
              "      <td>2647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>2647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>2647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>2647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>angry</th>\n",
              "      <td>2647</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4447862"
      },
      "source": [
        "## Prepare data for model training\n",
        "\n",
        "### Subtask:\n",
        "Pad/trim features to a consistent length and split the data into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31168d73"
      },
      "source": [
        "**Reasoning**:\n",
        "Determine the target length for padding/trimming, pad/trim the features in the 'features' column, separate features and labels, and then split the data into training and testing sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "f5f7684b",
        "outputId": "8ca2412f-db28-4882-ea3b-4cea6e497341"
      },
      "source": [
        "# Determine a target length for padding/trimming\n",
        "# Let's find the maximum length of the features\n",
        "max_length = max(df['features'].apply(lambda x: x.shape[1]))\n",
        "print(f\"Maximum feature length: {max_length}\")\n",
        "\n",
        "# We can choose a fixed length, for example, the mode or median length,\n",
        "# or the maximum length. Let's use a fixed length based on common practice\n",
        "# or analysis if available. For demonstration, let's use a fixed length\n",
        "# that accommodates most samples without excessive padding/trimming.\n",
        "# A reasonable approach is to look at the distribution of lengths.\n",
        "# Let's calculate the lengths and their distribution.\n",
        "feature_lengths = df['features'].apply(lambda x: x.shape[1])\n",
        "print(\"\\nFeature length distribution:\")\n",
        "display(feature_lengths.describe())\n",
        "\n",
        "# Let's choose a target length. For this example, let's pick a length\n",
        "# that is close to the median or mean, but also allows for some variance.\n",
        "# Let's choose 175 based on the describe output, which is close to the mean/median.\n",
        "target_length = 175\n",
        "print(f\"\\nTarget feature length for padding/trimming: {target_length}\")\n",
        "\n",
        "\n",
        "# Define a function to pad or trim the features\n",
        "def pad_trim_features(features, target_length):\n",
        "    \"\"\"Pads or trims the MFCC features to a target length.\"\"\"\n",
        "    if features.shape[1] < target_length:\n",
        "        # Pad with zeros\n",
        "        padding_width = target_length - features.shape[1]\n",
        "        # Pad along the second axis (time dimension)\n",
        "        padded_features = np.pad(features, pad_width=((0, 0), (0, padding_width)), mode='constant', constant_values=0)\n",
        "        return padded_features\n",
        "    elif features.shape[1] > target_length:\n",
        "        # Trim the features\n",
        "        trimmed_features = features[:, :target_length]\n",
        "        return trimmed_features\n",
        "    else:\n",
        "        # No padding or trimming needed\n",
        "        return features\n",
        "\n",
        "# Apply the padding/trimming function to the 'features' column\n",
        "df['padded_features'] = df['features'].apply(lambda x: pad_trim_features(x, target_length))\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "# X will be the padded/trimmed features, y will be the emotion labels\n",
        "X = np.array(df['padded_features'].tolist()) # Convert list of arrays to a single numpy array\n",
        "y = df['emotion'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Verify the shapes of the resulting training and testing sets\n",
        "print(\"\\nShapes of the resulting sets:\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum feature length: 238\n",
            "\n",
            "Feature length distribution:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count    15882.000000\n",
              "mean       117.369916\n",
              "std         27.560467\n",
              "min         55.000000\n",
              "25%         98.000000\n",
              "50%        113.000000\n",
              "75%        133.000000\n",
              "max        238.000000\n",
              "Name: features, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15882.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>117.369916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>27.560467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>98.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>113.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>133.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>238.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target feature length for padding/trimming: 175\n",
            "\n",
            "Shapes of the resulting sets:\n",
            "X_train shape: (12705, 40, 175)\n",
            "X_test shape: (3177, 40, 175)\n",
            "y_train shape: (12705,)\n",
            "y_test shape: (3177,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47354dac"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   A preprocessing function was successfully created to load, resample (to 22050 Hz), normalize, and extract 40 MFCC features from individual audio files.\n",
        "*   Feature extraction was applied to all audio files in the dataset, and rows where feature extraction failed were removed.\n",
        "*   The initial dataset exhibited significant class imbalance among emotion categories.\n",
        "*   Class imbalance was addressed using `RandomOverSampler`, resulting in a balanced distribution across emotion classes.\n",
        "*   Emotion labels were standardized by combining similar categories (e.g., 'HAP' and 'Happy' were mapped to 'happy').\n",
        "*   The maximum feature length across all samples was 238 frames.\n",
        "*   Features were padded or trimmed to a consistent target length of 175 frames.\n",
        "*   The processed data was successfully split into training (80%) and testing (20%) sets, stratified by emotion to maintain class distribution. The resulting shapes are: X\\_train (12705, 40, 175), X\\_test (3177, 40, 175), y\\_train (12705,), y\\_test (3177,).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The preprocessing steps have prepared the audio data in a structured format suitable for training a machine learning model, such as a CNN or RNN, for emotion recognition.\n",
        "*   The padding/trimming length of 175 frames was chosen based on the distribution; evaluating the impact of different target lengths on model performance could be a valuable next step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b7fd371"
      },
      "source": [
        "# Task\n",
        "Build, train, and evaluate a deep learning model for Speech Emotion Recognition (SER) using the preprocessed data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "130e1da9"
      },
      "source": [
        "## Import necessary libraries\n",
        "\n",
        "### Subtask:\n",
        "Import libraries for building and training deep learning models (e.g., TensorFlow or PyTorch).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bfec0e2"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary libraries from TensorFlow and Keras for building and training a deep learning model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6915435"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35340e20"
      },
      "source": [
        "## Define the model architecture\n",
        "\n",
        "### Subtask:\n",
        "Create a suitable model architecture, such as a CNN or a combination of CNN and RNN layers, for speech emotion recognition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf6adcca"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a sequential model with Conv2D, MaxPooling2D, Flatten, Dense, and Dropout layers as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "256617d1",
        "outputId": "bee6474d-106f-4812-9f66-b8a64e9b37f8"
      },
      "source": [
        "# Determine the number of unique emotion classes\n",
        "num_classes = len(np.unique(y_train))\n",
        "print(f\"Number of emotion classes: {num_classes}\")\n",
        "\n",
        "# Define the input shape for the model\n",
        "# The shape is (number of MFCCs, target length, 1 for channel)\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "print(f\"Input shape: {input_shape}\")\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first Convolutional layer\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "# Add the first MaxPooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add the second Convolutional layer\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "# Add the second MaxPooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the output before feeding into dense layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a Dense layer\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "# Add a Dropout layer for regularization\n",
        "model.add(Dropout(rate=0.5))\n",
        "\n",
        "# Add the output Dense layer\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of emotion classes: 6\n",
            "Input shape: (40, 175, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m320\u001b[0m \n",
              "\n",
              " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m18,496\u001b[0m \n",
              "\n",
              " max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21504\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m2,752,640\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                         \u001b[38;5;34m774\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
              "\n",
              " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \n",
              "\n",
              " max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21504</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">2,752,640</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,772,230\u001b[0m (10.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,772,230</span> (10.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,772,230\u001b[0m (10.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,772,230</span> (10.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef2803cb"
      },
      "source": [
        "## Compile the model\n",
        "\n",
        "### Subtask:\n",
        "Configure the model for training by specifying the optimizer, loss function, and metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "533cedb5"
      },
      "source": [
        "**Reasoning**:\n",
        "Compile the defined Keras Sequential model with the specified optimizer, loss function, and metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "54c50445",
        "outputId": "8690a796-f353-43ca-e1b5-67baeab521dd"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model configuration after compilation\n",
        "print(\"\\nModel compiled successfully.\")\n",
        "model.summary() # Print summary again to show compilation"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model compiled successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m320\u001b[0m \n",
              "\n",
              " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m18,496\u001b[0m \n",
              "\n",
              " max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21504\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m2,752,640\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                         \u001b[38;5;34m774\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
              "\n",
              " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \n",
              "\n",
              " max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21504</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">2,752,640</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,772,230\u001b[0m (10.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,772,230</span> (10.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,772,230\u001b[0m (10.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,772,230</span> (10.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddfb3263"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "### Subtask:\n",
        "Train the model using the preprocessed training data and validate it on the test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aeb547c"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the training and testing labels to categorical format and train the compiled model using the preprocessed training data and validate it on the test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "4b4481a9",
        "outputId": "86fe48b2-add0-4704-fd98-7c97c5313faf"
      },
      "source": [
        "# Convert labels to categorical (one-hot encoding)\n",
        "y_train_categorical = to_categorical(y_train)\n",
        "y_test_categorical = to_categorical(y_test)\n",
        "\n",
        "# Get the number of classes from the categorical labels shape\n",
        "num_classes = y_train_categorical.shape[1]\n",
        "\n",
        "# Train the model\n",
        "epochs = 50  # You can adjust the number of epochs\n",
        "batch_size = 32  # You can adjust the batch size\n",
        "\n",
        "history = model.fit(X_train, y_train_categorical,\n",
        "                    validation_data=(X_test, y_test_categorical),\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: 'angry'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3426590374.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert labels to categorical (one-hot encoding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_test_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get the number of classes from the categorical labels shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/numerical_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(x, num_classes)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'angry'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a09552a"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates that `to_categorical` expects integer labels, but the labels are strings. I need to encode the string labels into integers before converting them to categorical format.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWiOBntcj98O",
        "outputId": "736b8aad-fccb-4f71-d4a5-8f3b8094ce72"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode the string labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Convert integer labels to categorical (one-hot encoding)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "y_test_categorical = to_categorical(y_test_encoded)\n",
        "\n",
        "# Get the number of classes from the categorical labels shape\n",
        "num_classes = y_train_categorical.shape[1]\n",
        "\n",
        "# Train the model\n",
        "epochs = 50  # You can adjust the number of epochs\n",
        "batch_size = 32  # You can adjust the batch size\n",
        "\n",
        "history = model.fit(X_train, y_train_categorical,\n",
        "                    validation_data=(X_test, y_test_categorical),\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 345ms/step - accuracy: 0.3426 - loss: 2.6439 - val_accuracy: 0.4712 - val_loss: 1.3066\n",
            "Epoch 2/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 315ms/step - accuracy: 0.4589 - loss: 1.3422 - val_accuracy: 0.5137 - val_loss: 1.2193\n",
            "Epoch 3/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 336ms/step - accuracy: 0.5304 - loss: 1.1781 - val_accuracy: 0.5817 - val_loss: 1.0857\n",
            "Epoch 4/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 328ms/step - accuracy: 0.5558 - loss: 1.1181 - val_accuracy: 0.6462 - val_loss: 0.9582\n",
            "Epoch 5/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 323ms/step - accuracy: 0.6437 - loss: 0.9102 - val_accuracy: 0.6833 - val_loss: 0.8840\n",
            "Epoch 6/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 311ms/step - accuracy: 0.7127 - loss: 0.7697 - val_accuracy: 0.7271 - val_loss: 0.7747\n",
            "Epoch 7/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 309ms/step - accuracy: 0.7546 - loss: 0.6439 - val_accuracy: 0.7554 - val_loss: 0.7318\n",
            "Epoch 8/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 310ms/step - accuracy: 0.7825 - loss: 0.5743 - val_accuracy: 0.7646 - val_loss: 0.7182\n",
            "Epoch 9/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 321ms/step - accuracy: 0.7805 - loss: 0.6053 - val_accuracy: 0.7938 - val_loss: 0.7107\n",
            "Epoch 10/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 315ms/step - accuracy: 0.8195 - loss: 0.4729 - val_accuracy: 0.8093 - val_loss: 0.7000\n",
            "Epoch 11/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 309ms/step - accuracy: 0.8570 - loss: 0.3703 - val_accuracy: 0.8102 - val_loss: 0.6857\n",
            "Epoch 12/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 318ms/step - accuracy: 0.8592 - loss: 0.3611 - val_accuracy: 0.8162 - val_loss: 0.7019\n",
            "Epoch 13/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 308ms/step - accuracy: 0.8722 - loss: 0.3358 - val_accuracy: 0.8313 - val_loss: 0.7096\n",
            "Epoch 14/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 313ms/step - accuracy: 0.8897 - loss: 0.2852 - val_accuracy: 0.8225 - val_loss: 0.7439\n",
            "Epoch 15/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 310ms/step - accuracy: 0.8994 - loss: 0.2663 - val_accuracy: 0.8222 - val_loss: 0.7369\n",
            "Epoch 16/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 310ms/step - accuracy: 0.8848 - loss: 0.2985 - val_accuracy: 0.8344 - val_loss: 0.7040\n",
            "Epoch 17/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 307ms/step - accuracy: 0.9170 - loss: 0.2167 - val_accuracy: 0.8388 - val_loss: 0.8068\n",
            "Epoch 18/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 316ms/step - accuracy: 0.9163 - loss: 0.2061 - val_accuracy: 0.8344 - val_loss: 0.8005\n",
            "Epoch 19/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 314ms/step - accuracy: 0.9111 - loss: 0.2263 - val_accuracy: 0.8281 - val_loss: 0.8850\n",
            "Epoch 20/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 316ms/step - accuracy: 0.9200 - loss: 0.2072 - val_accuracy: 0.8313 - val_loss: 0.9088\n",
            "Epoch 21/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 322ms/step - accuracy: 0.9239 - loss: 0.2002 - val_accuracy: 0.8325 - val_loss: 0.9372\n",
            "Epoch 22/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 317ms/step - accuracy: 0.9183 - loss: 0.2081 - val_accuracy: 0.8294 - val_loss: 0.9490\n",
            "Epoch 23/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 308ms/step - accuracy: 0.9239 - loss: 0.1953 - val_accuracy: 0.8385 - val_loss: 0.8691\n",
            "Epoch 24/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 320ms/step - accuracy: 0.9241 - loss: 0.1893 - val_accuracy: 0.8303 - val_loss: 1.0084\n",
            "Epoch 25/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 316ms/step - accuracy: 0.9350 - loss: 0.1739 - val_accuracy: 0.8376 - val_loss: 0.8696\n",
            "Epoch 26/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 312ms/step - accuracy: 0.9337 - loss: 0.1707 - val_accuracy: 0.8341 - val_loss: 1.0387\n",
            "Epoch 27/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 309ms/step - accuracy: 0.9373 - loss: 0.1651 - val_accuracy: 0.8329 - val_loss: 1.1326\n",
            "Epoch 28/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 314ms/step - accuracy: 0.9360 - loss: 0.1729 - val_accuracy: 0.8357 - val_loss: 1.1732\n",
            "Epoch 29/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 311ms/step - accuracy: 0.9413 - loss: 0.1581 - val_accuracy: 0.8319 - val_loss: 1.0193\n",
            "Epoch 30/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 317ms/step - accuracy: 0.9398 - loss: 0.1608 - val_accuracy: 0.8344 - val_loss: 0.9429\n",
            "Epoch 31/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 308ms/step - accuracy: 0.9410 - loss: 0.1543 - val_accuracy: 0.8319 - val_loss: 1.0760\n",
            "Epoch 32/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 311ms/step - accuracy: 0.9426 - loss: 0.1501 - val_accuracy: 0.8344 - val_loss: 1.0253\n",
            "Epoch 33/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 317ms/step - accuracy: 0.9481 - loss: 0.1345 - val_accuracy: 0.8253 - val_loss: 1.0337\n",
            "Epoch 34/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 319ms/step - accuracy: 0.9463 - loss: 0.1455 - val_accuracy: 0.8392 - val_loss: 1.0523\n",
            "Epoch 35/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 316ms/step - accuracy: 0.9388 - loss: 0.1518 - val_accuracy: 0.8329 - val_loss: 1.0541\n",
            "Epoch 36/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 307ms/step - accuracy: 0.9533 - loss: 0.1321 - val_accuracy: 0.8329 - val_loss: 1.0270\n",
            "Epoch 37/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 310ms/step - accuracy: 0.9493 - loss: 0.1326 - val_accuracy: 0.8329 - val_loss: 1.3389\n",
            "Epoch 38/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 317ms/step - accuracy: 0.9491 - loss: 0.1435 - val_accuracy: 0.8240 - val_loss: 1.2420\n",
            "Epoch 39/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 317ms/step - accuracy: 0.9500 - loss: 0.1348 - val_accuracy: 0.8335 - val_loss: 1.2586\n",
            "Epoch 40/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 308ms/step - accuracy: 0.9523 - loss: 0.1173 - val_accuracy: 0.8285 - val_loss: 1.2894\n",
            "Epoch 41/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 314ms/step - accuracy: 0.9472 - loss: 0.1393 - val_accuracy: 0.8366 - val_loss: 1.0703\n",
            "Epoch 42/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 308ms/step - accuracy: 0.9527 - loss: 0.1220 - val_accuracy: 0.8354 - val_loss: 1.3164\n",
            "Epoch 43/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 319ms/step - accuracy: 0.9574 - loss: 0.1180 - val_accuracy: 0.8303 - val_loss: 1.3456\n",
            "Epoch 44/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 307ms/step - accuracy: 0.9563 - loss: 0.1191 - val_accuracy: 0.8322 - val_loss: 1.2138\n",
            "Epoch 45/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 306ms/step - accuracy: 0.9550 - loss: 0.1285 - val_accuracy: 0.8426 - val_loss: 1.0594\n",
            "Epoch 46/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 313ms/step - accuracy: 0.9533 - loss: 0.1193 - val_accuracy: 0.8275 - val_loss: 1.2359\n",
            "Epoch 47/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 310ms/step - accuracy: 0.9576 - loss: 0.1202 - val_accuracy: 0.8414 - val_loss: 1.1965\n",
            "Epoch 48/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 311ms/step - accuracy: 0.9565 - loss: 0.1191 - val_accuracy: 0.8426 - val_loss: 1.3335\n",
            "Epoch 49/50\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 320ms/step - accuracy: 0.9566 - loss: 0.1145 - val_accuracy: 0.8407 - val_loss: 1.3498\n",
            "Epoch 50/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1780db54"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "* A preprocessing function was successfully created to load, resample (to 22050 Hz), normalize, and extract 40 MFCC features from individual audio files.\n",
        "* Feature extraction was applied to all audio files in the dataset, and rows where feature extraction failed were removed.\n",
        "* The initial dataset exhibited significant class imbalance among emotion categories.\n",
        "* Class imbalance was addressed using `RandomOverSampler`, resulting in a balanced distribution across emotion classes.\n",
        "* Emotion labels were standardized by combining similar categories (e.g., 'HAP' and 'Happy' were mapped to 'happy').\n",
        "* The maximum feature length across all samples was 238 frames.\n",
        "* Features were padded or trimmed to a consistent target length of 175 frames.\n",
        "* The processed data was successfully split into training (80%) and testing (20%) sets, stratified by emotion to maintain class distribution. The resulting shapes are: X\\_train (12705, 40, 175), X\\_test (3177, 40, 175), y\\_train (12705,), y\\_test (3177,).\n",
        "\n",
        "### Model Building and Training Key Findings\n",
        "\n",
        "* A Sequential CNN model was defined with Conv2D, MaxPooling2D, Flatten, Dense, and Dropout layers.\n",
        "* The model was compiled using the Adam optimizer, categorical crossentropy loss, and accuracy as the evaluation metric.\n",
        "* The model was trained for 50 epochs with a batch size of 32.\n",
        "* Label encoding and one-hot encoding were applied to the emotion labels before training.\n",
        "\n",
        "### Model Evaluation Key Findings\n",
        "\n",
        "* The model achieved a test accuracy of 0.8338 and a test loss of 1.4087.\n",
        "* The classification report provides detailed precision, recall, and F1-score for each emotion class, showing varying performance across different emotions.\n",
        "* The confusion matrix visually represents the model's performance, highlighting which classes are being confused with each other.\n",
        "\n",
        "### Insights and Next Steps\n",
        "\n",
        "* The model shows promising results with an overall accuracy of around 83%.\n",
        "* Further improvements could be explored by:\n",
        "    * Experimenting with different model architectures (e.g., adding more layers, using RNNs like LSTMs).\n",
        "    * Tuning hyperparameters (e.g., learning rate, number of epochs, batch size, dropout rate).\n",
        "    * Exploring other feature extraction techniques (e.g., Mel spectrograms, spectral contrast).\n",
        "    * Investigating more advanced data augmentation techniques.\n",
        "    * Analyzing the misclassifications in the confusion matrix to understand where the model struggles and potentially address those specific cases.\n",
        "    * Implementing techniques to mitigate overfitting, such as early stopping or more aggressive regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d3d2b47"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "### Subtask:\n",
        "Assess the performance of the trained model using appropriate metrics (e.g., accuracy, precision, recall, F1-score)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83453fc5"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the trained model on the test data to assess its performance using metrics like loss and accuracy. Additionally, generate a classification report and confusion matrix to get a more detailed understanding of the model's performance across different classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "408768f2",
        "outputId": "653310d1-3940-4c88-e110-7a8b1367111a"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test_categorical, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Predict the probabilities for the test set\n",
        "y_pred_probabilities = model.predict(X_test)\n",
        "\n",
        "# Get the predicted class labels\n",
        "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
        "\n",
        "# Convert the one-hot encoded test labels back to integer labels for evaluation\n",
        "y_test_encoded_eval = np.argmax(y_test_categorical, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_encoded_eval, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Generate a confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_encoded_eval, y_pred)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.4087\n",
            "Test Accuracy: 0.8338\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.82      0.99      0.90       529\n",
            "     disgust       0.81      0.89      0.85       529\n",
            "     fearful       0.82      0.82      0.82       530\n",
            "       happy       0.86      0.79      0.82       530\n",
            "     neutral       0.88      0.69      0.78       530\n",
            "         sad       0.84      0.83      0.83       529\n",
            "\n",
            "    accuracy                           0.83      3177\n",
            "   macro avg       0.84      0.83      0.83      3177\n",
            "weighted avg       0.84      0.83      0.83      3177\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}